# orchestration/pipeline_runner.py

import os
import time

# Step-wise imports
from ingestion.simulate_stream import simulate_stream
from processing.process_data import process_data
from transformation.transform_data import transform_data
from warehouse.load_to_sqlite import load_to_sqlite
from visualization.visualize import visualize_data

def run_pipeline():
    print("="*50)
    print("ğŸš€ Running ShopStream Data Pipeline")
    print("="*50)

    try:
        # Step 1: Simulate Ingestion
        print("\nğŸ”„ Step 1: Simulating Data Stream...")
        simulate_stream(delay=0.2)  # Faster for demo

        # Step 2: Data Cleaning
        print("\nğŸ§¹ Step 2: Processing Streamed Data...")
        process_data()

        # Step 3: Transformation
        print("\nğŸ“Š Step 3: Transforming Data...")
        transform_data()

        # Step 4: Load to Warehouse
        print("\nğŸ¢ Step 4: Loading Data to SQLite Warehouse...")
        load_to_sqlite()

        # Step 5: Visualization
        print("\nğŸ“ˆ Step 5: Visualizing Results...")
        visualize_data()

        print("\nâœ… Pipeline Completed Successfully!")
        print("ğŸ“ Visualization saved at: visualization/output_sales_chart.png")
        print("ğŸ“ SQLite DB created at: data/shopstream_warehouse.db")

    except Exception as e:
        print(f"\nâŒ Pipeline failed: {e}")

if __name__ == "__main__":
    run_pipeline()
